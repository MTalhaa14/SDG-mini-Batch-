# -*- coding: utf-8 -*-
"""Mini

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1we2hsH3FKQ1vCgECiNfI6E5QMmhlX5CO
"""

# Import necessary libraries
import numpy as np
import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load iris dataset
iris = load_iris()
X, Y = iris.data, iris.target

# Standardize the features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split data into train and test sets
x_train , x_test , y_train , y_test =  train_test_split(X,Y,test_size=0.3)

# Define ANN model
model = tf.keras.Sequential([
  tf.keras.layers.Flatten(input_shape=(4,)),
  tf.keras.layers.Dense(50, activation='relu'),
  tf.keras.layers.Dense(3, activation='softmax')
])

# Compile the model
model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])

# Set batch size and number of epochs
batch_size = 10
epochs = 100

# Train the model using mini-batch SGD
history = model.fit(x_train, tf.keras.utils.to_categorical(y_train, num_classes=3), batch_size=batch_size, epochs=epochs, validation_data=(x_test, tf.keras.utils.to_categorical(y_test, num_classes=3)))

# Plot the loss graph
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()